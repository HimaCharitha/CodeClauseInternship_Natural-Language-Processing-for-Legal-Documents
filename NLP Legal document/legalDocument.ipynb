{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google-t5/t5-small and revision d769bba (https://huggingface.co/google-t5/t5-small).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import os \n",
    "from transformers import pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "summarizer = pipeline(\"summarization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clauses(text):\n",
    "    doc = nlp(text)\n",
    "    clauses = []\n",
    "    for sent in doc.sents:\n",
    "        if \"section\" in sent.text.lower() or \"clause\" in sent.text.lower():\n",
    "            clauses.append(sent.text)\n",
    "    return clauses\n",
    "\n",
    "def summarize_clauses(clauses):\n",
    "    summaries = []\n",
    "    for clause in clauses:\n",
    "        summary = summarizer(clause, max_length=130, min_length=30, do_sample=False)\n",
    "        summaries.append(summary[0]['summary_text'])\n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 130, but your input_length is only 39. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 Summary:\n",
      "service provider agrees to provide graphic design services as requested by client . fee refers to compensation for services as described in section 4 .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def main():\n",
    "    current_dir = os.getcwd()\n",
    "    file_path = os.path.join(current_dir, 'data', 'legal_document.txt')\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            text = file.read().lower()  \n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return\n",
    "    \n",
    "    clauses = extract_clauses(text)\n",
    "\n",
    "    if not clauses:\n",
    "        print(\"No clauses found in the document.\")\n",
    "        return\n",
    "\n",
    "    summaries = summarize_clauses(clauses)\n",
    "    for i, summary in enumerate(summaries):\n",
    "        print(f\"Clause {i+1} Summary:\")\n",
    "        print(summary)\n",
    "        print(\"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
